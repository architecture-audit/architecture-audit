{"custom_id":"aws_streaming_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_streaming_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_batch_processing_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_machine_learning_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_business_intelligence_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"aws_data_science_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: aws\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for aws\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real aws instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_streaming_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_batch_processing_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_machine_learning_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_business_intelligence_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"azure_data_science_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: azure\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for azure\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real azure instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_streaming_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: streaming\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For streaming workloads, use streaming-optimized clusters with Delta Live Tables for real-time processing\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_batch_processing_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: batch_processing\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For batch processing, use standard or high-concurrency clusters depending on job isolation needs\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_machine_learning_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: machine_learning\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For ML workloads, use ML-optimized clusters with GPU support for training and inference\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_business_intelligence_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: business_intelligence\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For BI workloads, use SQL warehouses or high-concurrency clusters for concurrent query performance\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_small_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: small (less than 1TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_medium_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: medium (1-10TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_large_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: large (10-100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_small_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_small_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_small_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_small_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: small (1-10 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_medium_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_medium_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_medium_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_medium_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: medium (10-50 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_large_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_large_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_large_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_large_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: large (50-200 concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_xlarge_cost","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: cost (minimize cost)\nSLA Requirement: basic\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For cost priority: minimize instance sizes, maximize spot usage, consider serverless for variable workloads\n- For \n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_xlarge_performance","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: performance (maximum performance)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For performance priority: use memory-optimized instances, enable Photon acceleration, minimize spot usage\n- For \n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_xlarge_reliability","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: reliability (high reliability and uptime)\nSLA Requirement: critical\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For reliability priority: use on-demand instances only, enable auto-scaling, implement multi-AZ redundancy\n- For \n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}
{"custom_id":"gcp_data_science_xlarge_xlarge_balanced","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You are a Databricks architecture expert with deep knowledge of cluster configurations, performance optimization, and cost management. Always provide detailed explanations for your recommendations. Respond with valid JSON only, no markdown formatting."},{"role":"user","content":"As a Databricks sizing expert, provide a specific recommendation for:\n\nCloud Provider: gcp\nWorkload Type: data_science\nData Scale: xlarge (over 100TB daily processing)\nTeam Size: xlarge (200+ concurrent users)\nPriority: balanced (balanced cost and performance)\nSLA Requirement: standard\n\nImportant architectural considerations:\n- For data science, use ML clusters with notebook support and collaborative features\n- For \n- For \n- For \n- For balanced approach: mix of spot and on-demand, moderate instance sizes, selective Photon usage\n\nCluster type selection logic:\n- streaming workload → streaming or serverless cluster\n- batch_processing → standard or highconcurrency based on isolation needs\n- machine_learning → ml cluster with GPU support if needed\n- business_intelligence → sql warehouse or highconcurrency for concurrency\n- data_science → ml cluster for notebook collaboration\n\nProvide a JSON response with EXACTLY this format (no markdown, just JSON):\n{\n  \"instanceType\": \"specific instance type for gcp\",\n  \"nodeCount\": number,\n  \"clusterType\": \"one of: standard, highconcurrency, ml, sql, streaming, serverless\",\n  \"spotInstancePercent\": number (0-100),\n  \"reservedInstancePercent\": number (0-100),\n  \"features\": {\n    \"photon\": boolean,\n    \"autoScaling\": boolean,\n    \"unityCatalog\": boolean,\n    \"deltaLiveTables\": boolean\n  },\n  \"estimatedMonthlyCost\": number (USD),\n  \"confidence\": number (0-100),\n  \"explanation\": [\n    \"Detailed reason for selecting cluster type\",\n    \"Justification for instance type based on data scale\",\n    \"Node count calculation based on team size and workload\",\n    \"Cost optimization strategy for priority\",\n    \"Feature enablement rationale\"\n  ],\n  \"pros\": [\"array\", \"of\", \"specific\", \"advantages\"],\n  \"cons\": [\"array\", \"of\", \"specific\", \"tradeoffs\"]\n}\n\nEnsure the explanation array contains detailed, specific reasons for each architectural decision.\nUse real gcp instance types and realistic pricing based on current market rates."}],"temperature":0.1,"max_tokens":1000}}